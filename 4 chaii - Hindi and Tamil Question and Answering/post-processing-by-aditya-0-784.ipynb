{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64521d31",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-08-13T11:16:10.441619Z",
     "iopub.status.busy": "2021-08-13T11:16:10.441265Z",
     "iopub.status.idle": "2021-08-13T11:16:20.513927Z",
     "shell.execute_reply": "2021-08-13T11:16:20.512906Z",
     "shell.execute_reply.started": "2021-08-13T11:16:10.441541Z"
    },
    "papermill": {
     "duration": 0.011425,
     "end_time": "2021-11-08T12:22:47.258689",
     "exception": false,
     "start_time": "2021-11-08T12:22:47.247264",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Special thanks to @abhishek and @nbroad for their notebooks:\n",
    "\n",
    "https://www.kaggle.com/abhishek/hello-friends-chaii-pi-lo\n",
    "\n",
    "https://www.kaggle.com/nbroad/chaii-qa-torch-5-fold-with-post-processing-765\n",
    "\n",
    "Please upvote them!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaaecb23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-08T12:22:47.284419Z",
     "iopub.status.busy": "2021-11-08T12:22:47.282897Z",
     "iopub.status.idle": "2021-11-08T12:22:57.315067Z",
     "shell.execute_reply": "2021-11-08T12:22:57.314405Z"
    },
    "papermill": {
     "duration": 10.046599,
     "end_time": "2021-11-08T12:22:57.315213",
     "exception": false,
     "start_time": "2021-11-08T12:22:47.268614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-cloud 0.1.13 requires tensorflow<3.0,>=1.15.0, which is not installed.\r\n",
      "dask-cudf 21.6.1+2.g101fc0fda4 requires cupy-cuda112, which is not installed.\r\n",
      "cudf 21.6.1+2.g101fc0fda4 requires cupy-cuda110, which is not installed.\r\n",
      "s3fs 2021.6.1 requires fsspec==2021.06.1, but you have fsspec 2021.6.0 which is incompatible.\r\n",
      "pytorch-lightning 1.3.8 requires fsspec[http]!=2021.06.0,>=2021.05.0, but you have fsspec 2021.6.0 which is incompatible.\r\n",
      "dask-cudf 21.6.1+2.g101fc0fda4 requires dask<=2021.5.1,>=2021.4.0, but you have dask 2021.6.2 which is incompatible.\r\n",
      "dask-cudf 21.6.1+2.g101fc0fda4 requires distributed<=2021.5.1,>=2.22.0, but you have distributed 2021.6.2 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall fsspec -qq -y\n",
    "!pip install --no-index --find-links ../input/hf-datasets/wheels datasets -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b265feb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-08T12:22:57.342320Z",
     "iopub.status.busy": "2021-11-08T12:22:57.341548Z",
     "iopub.status.idle": "2021-11-08T12:23:00.632087Z",
     "shell.execute_reply": "2021-11-08T12:23:00.631516Z",
     "shell.execute_reply.started": "2021-08-13T11:16:20.517947Z"
    },
    "papermill": {
     "duration": 3.305929,
     "end_time": "2021-11-08T12:23:00.632222",
     "exception": false,
     "start_time": "2021-11-08T12:22:57.326293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../input/tez-lib/\")\n",
    "import collections\n",
    "import numpy as np\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from sklearn import metrics\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import tez\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "633bab84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-08T12:23:00.669092Z",
     "iopub.status.busy": "2021-11-08T12:23:00.667903Z",
     "iopub.status.idle": "2021-11-08T12:23:00.670980Z",
     "shell.execute_reply": "2021-11-08T12:23:00.670467Z",
     "shell.execute_reply.started": "2021-08-13T11:16:23.625395Z"
    },
    "papermill": {
     "duration": 0.025947,
     "end_time": "2021-11-08T12:23:00.671117",
     "exception": false,
     "start_time": "2021-11-08T12:23:00.645170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ChaiiModel(tez.Model):\n",
    "    def __init__(self, model_name, num_train_steps, steps_per_epoch, learning_rate):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.model_name = model_name\n",
    "        self.num_train_steps = num_train_steps\n",
    "        self.step_scheduler_after = \"batch\"\n",
    "\n",
    "        hidden_dropout_prob: float = 0.0\n",
    "        layer_norm_eps: float = 1e-7\n",
    "\n",
    "        config = transformers.AutoConfig.from_pretrained(model_name)\n",
    "        config.update(\n",
    "            {\n",
    "                \"output_hidden_states\": True,\n",
    "                \"hidden_dropout_prob\": hidden_dropout_prob,\n",
    "                \"layer_norm_eps\": layer_norm_eps,\n",
    "                \"add_pooling_layer\": False,\n",
    "            }\n",
    "        )\n",
    "        self.transformer = transformers.AutoModel.from_pretrained(model_name, config=config)\n",
    "        self.output = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids=None, start_positions=None, end_positions=None):\n",
    "        transformer_out = self.transformer(ids, mask)\n",
    "        sequence_output = transformer_out[0]\n",
    "        logits = self.output(sequence_output)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1).contiguous()\n",
    "        end_logits = end_logits.squeeze(-1).contiguous()\n",
    "\n",
    "        return (start_logits, end_logits), 0, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "168251f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-08T12:23:00.701500Z",
     "iopub.status.busy": "2021-11-08T12:23:00.700059Z",
     "iopub.status.idle": "2021-11-08T12:23:00.703333Z",
     "shell.execute_reply": "2021-11-08T12:23:00.702718Z",
     "shell.execute_reply.started": "2021-08-13T11:16:23.639992Z"
    },
    "papermill": {
     "duration": 0.020531,
     "end_time": "2021-11-08T12:23:00.703484",
     "exception": false,
     "start_time": "2021-11-08T12:23:00.682953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ChaiiDataset:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return {\n",
    "            \"ids\": torch.tensor(self.data[item][\"input_ids\"], dtype=torch.long),\n",
    "            \"mask\": torch.tensor(self.data[item][\"attention_mask\"], dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f31e2d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-08T12:23:00.735832Z",
     "iopub.status.busy": "2021-11-08T12:23:00.734114Z",
     "iopub.status.idle": "2021-11-08T12:23:00.736657Z",
     "shell.execute_reply": "2021-11-08T12:23:00.737127Z",
     "shell.execute_reply.started": "2021-08-13T11:16:23.648932Z"
    },
    "papermill": {
     "duration": 0.022362,
     "end_time": "2021-11-08T12:23:00.737254",
     "exception": false,
     "start_time": "2021-11-08T12:23:00.714892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_validation_features(examples, tokenizer, pad_on_right, max_length, doc_stride):\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    tokenized_examples[\"example_id\"] = []\n",
    "\n",
    "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        context_index = 1 if pad_on_right else 0\n",
    "        sample_index = sample_mapping[i]\n",
    "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
    "        tokenized_examples[\"offset_mapping\"][i] = [\n",
    "            (o if sequence_ids[k] == context_index else None)\n",
    "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
    "        ]\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f750af9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-08T12:23:00.774692Z",
     "iopub.status.busy": "2021-11-08T12:23:00.773070Z",
     "iopub.status.idle": "2021-11-08T12:23:00.775631Z",
     "shell.execute_reply": "2021-11-08T12:23:00.776075Z",
     "shell.execute_reply.started": "2021-08-13T11:16:23.664073Z"
    },
    "papermill": {
     "duration": 0.027729,
     "end_time": "2021-11-08T12:23:00.776194",
     "exception": false,
     "start_time": "2021-11-08T12:23:00.748465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def postprocess_qa_predictions(\n",
    "    examples, tokenizer, features, raw_predictions, n_best_size=20, max_answer_length=30, squad_v2=False\n",
    "):\n",
    "    all_start_logits, all_end_logits = raw_predictions\n",
    "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "    features_per_example = collections.defaultdict(list)\n",
    "    for i, feature in enumerate(features):\n",
    "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
    "\n",
    "    predictions = collections.OrderedDict()\n",
    "\n",
    "    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n",
    "\n",
    "    for example_index, example in enumerate(tqdm(examples)):\n",
    "        feature_indices = features_per_example[example_index]\n",
    "\n",
    "        min_null_score = None  # Only used if squad_v2 is True.\n",
    "        valid_answers = []\n",
    "\n",
    "        context = example[\"context\"]\n",
    "        for feature_index in feature_indices:\n",
    "            start_logits = all_start_logits[feature_index]\n",
    "            end_logits = all_end_logits[feature_index]\n",
    "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
    "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
    "            if min_null_score is None or min_null_score < feature_null_score:\n",
    "                min_null_score = feature_null_score\n",
    "\n",
    "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    if (\n",
    "                        start_index >= len(offset_mapping)\n",
    "                        or end_index >= len(offset_mapping)\n",
    "                        or offset_mapping[start_index] is None\n",
    "                        or offset_mapping[end_index] is None\n",
    "                    ):\n",
    "                        continue\n",
    "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "                        continue\n",
    "\n",
    "                    start_char = offset_mapping[start_index][0]\n",
    "                    end_char = offset_mapping[end_index][1]\n",
    "                    valid_answers.append(\n",
    "                        {\n",
    "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                            \"text\": context[start_char:end_char],\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        if len(valid_answers) > 0:\n",
    "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
    "        else:\n",
    "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
    "\n",
    "        if not squad_v2:\n",
    "            predictions[example[\"id\"]] = best_answer[\"text\"]\n",
    "        else:\n",
    "            answer = best_answer[\"text\"] if best_answer[\"score\"] > min_null_score else \"\"\n",
    "            predictions[example[\"id\"]] = answer\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f75b7b4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-08T12:23:00.802425Z",
     "iopub.status.busy": "2021-11-08T12:23:00.801573Z",
     "iopub.status.idle": "2021-11-08T12:23:07.657488Z",
     "shell.execute_reply": "2021-11-08T12:23:07.657011Z",
     "shell.execute_reply.started": "2021-08-13T07:30:10.094474Z"
    },
    "papermill": {
     "duration": 6.87057,
     "end_time": "2021-11-08T12:23:07.657638",
     "exception": false,
     "start_time": "2021-11-08T12:23:00.787068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"../input/xlmrob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77939918",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-08T12:23:07.689680Z",
     "iopub.status.busy": "2021-11-08T12:23:07.689121Z",
     "iopub.status.idle": "2021-11-08T12:29:43.725315Z",
     "shell.execute_reply": "2021-11-08T12:29:43.723902Z"
    },
    "papermill": {
     "duration": 396.057225,
     "end_time": "2021-11-08T12:29:43.725485",
     "exception": false,
     "start_time": "2021-11-08T12:23:07.668260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1119d42ad01b4594982a4723f100d5a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5006c999c36f4726ac2b122969c95e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=81.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 10%|█         | 1/10 [01:04<09:41, 64.58s/it]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 20%|██        | 2/10 [01:52<07:19, 54.99s/it]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 30%|███       | 3/10 [02:28<05:24, 46.33s/it]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 40%|████      | 4/10 [03:03<04:10, 41.76s/it]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 50%|█████     | 5/10 [03:38<03:16, 39.22s/it]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 60%|██████    | 6/10 [04:13<02:31, 37.88s/it]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 70%|███████   | 7/10 [04:48<01:50, 36.87s/it]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 80%|████████  | 8/10 [05:24<01:13, 36.54s/it]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 90%|█████████ | 9/10 [06:00<00:36, 36.41s/it]Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 10/10 [06:35<00:00, 39.52s/it]\n"
     ]
    }
   ],
   "source": [
    "pad_on_right = tokenizer.padding_side == \"right\"\n",
    "max_length = 512\n",
    "doc_stride = 310\n",
    "\n",
    "test_data = pd.read_csv(\"../input/chaii-hindi-and-tamil-question-answering/test.csv\")\n",
    "test_dataset = Dataset.from_pandas(test_data)\n",
    "test_features = test_dataset.map(\n",
    "    partial(\n",
    "        prepare_validation_features, \n",
    "        tokenizer=tokenizer,\n",
    "        pad_on_right=pad_on_right, \n",
    "        max_length=max_length,\n",
    "        doc_stride=doc_stride\n",
    "    ),\n",
    "    batched=True,\n",
    "    remove_columns=test_dataset.column_names\n",
    ")\n",
    "test_feats_small = test_features.map(\n",
    "    lambda example: example, remove_columns=['example_id', 'offset_mapping']\n",
    ")\n",
    "\n",
    "fin_start_logits = None\n",
    "fin_end_logits = None\n",
    "\n",
    "for fold_ in tqdm(range(10)):\n",
    "    model = ChaiiModel(model_name=\"../input/xlmrob\", num_train_steps=0, steps_per_epoch=0, learning_rate=0)\n",
    "    model.load(f\"../input/deepsetsquad2-v2/pytorch_model_f{fold_}.bin\", weights_only=True)\n",
    "    model.to(\"cuda\")\n",
    "    model.eval()\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        ChaiiDataset(test_feats_small), \n",
    "        batch_size=32,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        shuffle=False\n",
    "    )\n",
    "    start_logits = []\n",
    "    end_logits = []\n",
    "\n",
    "    for b_idx, data in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            for key, value in data.items():\n",
    "                data[key] = value.to(\"cuda\")\n",
    "            output, _, _ = model(**data)\n",
    "            start = output[0].detach().cpu().numpy()\n",
    "            end = output[1].detach().cpu().numpy()\n",
    "            start_logits.append(start)\n",
    "            end_logits.append(end)\n",
    "\n",
    "    start_logits = np.vstack(start_logits)\n",
    "    end_logits = np.vstack(end_logits)\n",
    "    \n",
    "    if fin_start_logits is None:\n",
    "        fin_start_logits = start_logits\n",
    "        fin_end_logits = end_logits\n",
    "    else:\n",
    "        fin_start_logits += start_logits\n",
    "        fin_end_logits += end_logits\n",
    "        \n",
    "    del model\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90494af2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-08T12:29:43.771696Z",
     "iopub.status.busy": "2021-11-08T12:29:43.771110Z",
     "iopub.status.idle": "2021-11-08T12:29:43.775599Z",
     "shell.execute_reply": "2021-11-08T12:29:43.775140Z",
     "shell.execute_reply.started": "2021-08-13T07:41:23.628485Z"
    },
    "papermill": {
     "duration": 0.031677,
     "end_time": "2021-11-08T12:29:43.775732",
     "exception": false,
     "start_time": "2021-11-08T12:29:43.744055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fin_start_logits /= 13\n",
    "fin_end_logits /= 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6160fb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-08T12:29:43.816601Z",
     "iopub.status.busy": "2021-11-08T12:29:43.816111Z",
     "iopub.status.idle": "2021-11-08T12:29:44.453346Z",
     "shell.execute_reply": "2021-11-08T12:29:44.452732Z",
     "shell.execute_reply.started": "2021-08-13T07:43:13.949347Z"
    },
    "papermill": {
     "duration": 0.660518,
     "end_time": "2021-11-08T12:29:44.453520",
     "exception": false,
     "start_time": "2021-11-08T12:29:43.793002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing 5 example predictions split into 81 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 11.03it/s]\n"
     ]
    }
   ],
   "source": [
    "fin_preds = postprocess_qa_predictions(test_dataset, tokenizer, test_features, (fin_start_logits, fin_end_logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3247501a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-08T12:29:44.551921Z",
     "iopub.status.busy": "2021-11-08T12:29:44.528247Z",
     "iopub.status.idle": "2021-11-08T12:29:44.559616Z",
     "shell.execute_reply": "2021-11-08T12:29:44.560028Z",
     "shell.execute_reply.started": "2021-08-13T07:43:17.390549Z"
    },
    "papermill": {
     "duration": 0.086339,
     "end_time": "2021-11-08T12:29:44.560174",
     "exception": false,
     "start_time": "2021-11-08T12:29:44.473835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = []\n",
    "for p1, p2 in fin_preds.items():\n",
    "    p2 = \" \".join(p2.split())\n",
    "    p2 = p2.strip(punctuation)\n",
    "    submission.append((p1, p2))\n",
    "    \n",
    "sample = pd.DataFrame(submission, columns=[\"id\", \"PredictionString\"])\n",
    "\n",
    "test_data =pd.merge(left=test_data,right=sample,on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9348f5",
   "metadata": {
    "papermill": {
     "duration": 0.018425,
     "end_time": "2021-11-08T12:29:44.597653",
     "exception": false,
     "start_time": "2021-11-08T12:29:44.579228",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09060dfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-08T12:29:44.645923Z",
     "iopub.status.busy": "2021-11-08T12:29:44.645079Z",
     "iopub.status.idle": "2021-11-08T12:29:44.661529Z",
     "shell.execute_reply": "2021-11-08T12:29:44.661098Z",
     "shell.execute_reply.started": "2021-08-13T07:43:18.942846Z"
    },
    "papermill": {
     "duration": 0.045412,
     "end_time": "2021-11-08T12:29:44.661659",
     "exception": false,
     "start_time": "2021-11-08T12:29:44.616247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bad_starts = [\".\", \",\", \"(\", \")\", \"-\", \"–\",  \",\", \";\"]\n",
    "bad_endings = [\"...\", \"-\", \"(\", \")\", \"–\", \",\", \";\"]\n",
    "\n",
    "tamil_ad = \"கி.பி\"\n",
    "tamil_bc = \"கி.மு\"\n",
    "tamil_km = \"கி.மீ\"\n",
    "hindi_ad = \"ई\"\n",
    "hindi_bc = \"ई.पू\"\n",
    "\n",
    "\n",
    "cleaned_preds = []\n",
    "for pred, context in test_data[[\"PredictionString\", \"context\"]].to_numpy():\n",
    "    if pred == \"\":\n",
    "        cleaned_preds.append(pred)\n",
    "        continue\n",
    "    while any([pred.startswith(y) for y in bad_starts]):\n",
    "        pred = pred[1:]\n",
    "    while any([pred.endswith(y) for y in bad_endings]):\n",
    "        if pred.endswith(\"...\"):\n",
    "            pred = pred[:-3]\n",
    "        else:\n",
    "            pred = pred[:-1]\n",
    "    \n",
    "    if any([pred.endswith(tamil_ad), pred.endswith(tamil_bc), pred.endswith(tamil_km), pred.endswith(hindi_ad), pred.endswith(hindi_bc)]) and pred+\".\" in context:\n",
    "        pred = pred+\".\"\n",
    "\n",
    "    cleaned_preds.append(pred)\n",
    "\n",
    "test_data[\"PredictionString\"] = cleaned_preds\n",
    "test_data[['id', 'PredictionString']].to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 427.784985,
   "end_time": "2021-11-08T12:29:48.001486",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-08T12:22:40.216501",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "05abf747a62a4ced99e63a9c124bceed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1119d42ad01b4594982a4723f100d5a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6652a02be5bb4ac88789612111c0de43",
        "IPY_MODEL_1fed7467ddda404f988997e549e9debe"
       ],
       "layout": "IPY_MODEL_d39851d09a914e9aa5859d4c53412374"
      }
     },
     "1fed7467ddda404f988997e549e9debe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_74bb53f751c643daa53280b32a2ab14b",
       "placeholder": "​",
       "style": "IPY_MODEL_05abf747a62a4ced99e63a9c124bceed",
       "value": "&lt;tqdm.auto.tqdm object at 0x7f8c6abb0210&gt;"
      }
     },
     "33e61104522e4ab0b5dee36fc2ee2b8b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "34767bb0f92b4baab09241ab591caf96": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "37e769052abf476284adb67df54b3b27": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_33e61104522e4ab0b5dee36fc2ee2b8b",
       "placeholder": "​",
       "style": "IPY_MODEL_ee9ba1deb5174321960afcca5fbe9466",
       "value": "&lt;tqdm.auto.tqdm object at 0x7f8c6ab98990&gt;"
      }
     },
     "390904287f4148d196116e3db544c9ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bb5a508ff4ba465db361add0572fba21",
       "max": 81.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_975c7bd91cdd4aabbf44c5f594d96f9f",
       "value": 81.0
      }
     },
     "5006c999c36f4726ac2b122969c95e43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_390904287f4148d196116e3db544c9ed",
        "IPY_MODEL_37e769052abf476284adb67df54b3b27"
       ],
       "layout": "IPY_MODEL_34767bb0f92b4baab09241ab591caf96"
      }
     },
     "52fde44317a746f2904dbd7c8b6f65ec": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6652a02be5bb4ac88789612111c0de43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_52fde44317a746f2904dbd7c8b6f65ec",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d3d6bf901fb144a7865a1adce1b52cb7",
       "value": 1.0
      }
     },
     "74bb53f751c643daa53280b32a2ab14b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "975c7bd91cdd4aabbf44c5f594d96f9f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "bb5a508ff4ba465db361add0572fba21": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d39851d09a914e9aa5859d4c53412374": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d3d6bf901fb144a7865a1adce1b52cb7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "ee9ba1deb5174321960afcca5fbe9466": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
